{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "periodic-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PySPark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "published-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Spark UI\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-handle",
   "metadata": {},
   "source": [
    "#### Basics /PySpark Crash Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "retired-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attached-apple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accumulator',\n",
       " 'AccumulatorParam',\n",
       " 'Any',\n",
       " 'BarrierTaskContext',\n",
       " 'BarrierTaskInfo',\n",
       " 'BasicProfiler',\n",
       " 'Broadcast',\n",
       " 'CPickleSerializer',\n",
       " 'Callable',\n",
       " 'HiveContext',\n",
       " 'InheritableThread',\n",
       " 'MarshalSerializer',\n",
       " 'Optional',\n",
       " 'Profiler',\n",
       " 'RDD',\n",
       " 'RDDBarrier',\n",
       " 'Row',\n",
       " 'SQLContext',\n",
       " 'SparkConf',\n",
       " 'SparkContext',\n",
       " 'SparkFiles',\n",
       " 'SparkJobInfo',\n",
       " 'SparkStageInfo',\n",
       " 'StatusTracker',\n",
       " 'StorageLevel',\n",
       " 'TaskContext',\n",
       " 'TypeVar',\n",
       " 'Union',\n",
       " '_F',\n",
       " '_NoValue',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_globals',\n",
       " 'accumulators',\n",
       " 'broadcast',\n",
       " 'cast',\n",
       " 'cloudpickle',\n",
       " 'conf',\n",
       " 'context',\n",
       " 'copy_func',\n",
       " 'errors',\n",
       " 'files',\n",
       " 'filterwarnings',\n",
       " 'find_spark_home',\n",
       " 'inheritable_thread_target',\n",
       " 'java_gateway',\n",
       " 'join',\n",
       " 'keyword_only',\n",
       " 'profiler',\n",
       " 'rdd',\n",
       " 'rddsampler',\n",
       " 'resource',\n",
       " 'resultiterable',\n",
       " 'serializers',\n",
       " 'shuffle',\n",
       " 'since',\n",
       " 'sql',\n",
       " 'statcounter',\n",
       " 'status',\n",
       " 'storagelevel',\n",
       " 'taskcontext',\n",
       " 'traceback_utils',\n",
       " 'types',\n",
       " 'util',\n",
       " 'version',\n",
       " 'wraps']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Methods/Attrib\n",
    "dir(pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bulgarian-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session used for DF\n",
    "spark = SparkSession.builder.appName(\"MLwithSpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dated-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV without header/schema\n",
    "df = spark.read.csv(\"data/hcvdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "million-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "| _c0|          _c1|_c2|_c3| _c4| _c5| _c6| _c7| _c8|  _c9|_c10|_c11|_c12|_c13|\n",
      "+----+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|NULL|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "|   1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|   2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|   3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|   4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "+----+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview Data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conceptual-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV with header\n",
    "df = spark.read.csv(\"data/hcvdata.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "searching-pasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-bennett",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='1', Category='0=Blood Donor', Age='32', Sex='m', ALB='38.5', ALP='52.5', ALT='7.7', AST='22.1', BIL='7.5', CHE='6.93', CHOL='3.23', CREA='106', GGT='12.1', PROT='69')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get First Row\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "applied-relaxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='1', Category='0=Blood Donor', Age='32', Sex='m', ALB='38.5', ALP='52.5', ALT='7.7', AST='22.1', BIL='7.5', CHE='6.93', CHOL='3.23', CREA='106', GGT='12.1', PROT='69'),\n",
       " Row(_c0='2', Category='0=Blood Donor', Age='32', Sex='m', ALB='38.5', ALP='70.3', ALT='18', AST='24.7', BIL='3.9', CHE='11.17', CHOL='4.8', CREA='74', GGT='15.6', PROT='76.5'),\n",
       " Row(_c0='3', Category='0=Blood Donor', Age='32', Sex='m', ALB='46.9', ALP='74.7', ALT='36.2', AST='52.6', BIL='6.1', CHE='8.84', CHOL='5.2', CREA='86', GGT='33.2', PROT='79.3'),\n",
       " Row(_c0='4', Category='0=Blood Donor', Age='32', Sex='m', ALB='43.2', ALP='52', ALT='30.6', AST='22.6', BIL='18.9', CHE='7.33', CHOL='4.74', CREA='80', GGT='33.8', PROT='75.7'),\n",
       " Row(_c0='5', Category='0=Blood Donor', Age='32', Sex='m', ALB='39.2', ALP='74.1', ALT='32.6', AST='24.8', BIL='9.6', CHE='9.15', CHOL='4.32', CREA='76', GGT='29.9', PROT='68.7')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get  5 Head\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "established-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Category',\n",
       " 'Age',\n",
       " 'Sex',\n",
       " 'ALB',\n",
       " 'ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'BIL',\n",
       " 'CHE',\n",
       " 'CHOL',\n",
       " 'CREA',\n",
       " 'GGT',\n",
       " 'PROT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check For the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "african-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('Category', 'string'),\n",
       " ('Age', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('ALB', 'string'),\n",
       " ('ALP', 'string'),\n",
       " ('ALT', 'string'),\n",
       " ('AST', 'string'),\n",
       " ('BIL', 'string'),\n",
       " ('CHE', 'string'),\n",
       " ('CHOL', 'string'),\n",
       " ('CREA', 'string'),\n",
       " ('GGT', 'string'),\n",
       " ('PROT', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check For the Dtype\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modern-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- ALB: string (nullable = true)\n",
      " |-- ALP: string (nullable = true)\n",
      " |-- ALT: string (nullable = true)\n",
      " |-- AST: string (nullable = true)\n",
      " |-- BIL: string (nullable = true)\n",
      " |-- CHE: string (nullable = true)\n",
      " |-- CHOL: string (nullable = true)\n",
      " |-- CREA: string (nullable = true)\n",
      " |-- GGT: string (nullable = true)\n",
      " |-- PROT: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unusual-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "breathing-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "honest-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615 14\n"
     ]
    }
   ],
   "source": [
    "# Get the shape (rows,cols)\n",
    "print(df.count(),len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affecting-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Descriptive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electoral-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+\n",
      "|summary|               _c0|     Category|               Age| Sex|              ALB|               ALP|               ALT|              AST|               BIL|               CHE|              CHOL|             CREA|              GGT|             PROT|\n",
      "+-------+------------------+-------------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+\n",
      "|  count|               615|          615|               615| 615|              615|               615|               615|              615|               615|               615|               615|              615|              615|              615|\n",
      "|   mean|             308.0|         NULL| 47.40813008130081|NULL|41.62019543973941| 68.28391959798999| 28.45081433224754|34.78634146341462|11.396747967479675| 8.196634146341458| 5.368099173553719|81.28780487804877|39.53317073170732|72.04413680781768|\n",
      "| stddev|177.67948671695333|         NULL|10.055105445519239|NULL|5.780629404103076|26.028315300123676|25.469688813870942|33.09069033855156|19.673149805846588|2.2056572704292927|1.1327284311597354|49.75616601234976|54.66107123891245|5.402635737104955|\n",
      "|    min|                 1|0=Blood Donor|                19|   f|             14.9|             100.4|               0.9|             10.6|               0.8|              1.42|              1.43|              100|               10|             44.8|\n",
      "|    max|                99|  3=Cirrhosis|                77|   m|               NA|                NA|                NA|               99|                91|              9.99|                NA|               99|             99.7|               NA|\n",
      "+-------+------------------+-------------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "third-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|               615|\n",
      "|   mean| 47.40813008130081|\n",
      "| stddev|10.055105445519239|\n",
      "|    min|                19|\n",
      "|    max|                77|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Descriptive Summary of A Column\n",
    "df.describe('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selection of Columns\n",
    "+ Dont bring out the entire columne\n",
    "    - Bracket Notation df[col]\n",
    "    - Dot Notation df.col\n",
    "    \n",
    "+ df.select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "likely-guard",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Category',\n",
       " 'Age',\n",
       " 'Sex',\n",
       " 'ALB',\n",
       " 'ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'BIL',\n",
       " 'CHE',\n",
       " 'CHOL',\n",
       " 'CREA',\n",
       " 'GGT',\n",
       " 'PROT']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select A Column\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lesbian-jungle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selection\n",
    "df.select('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "falling-waste",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|AGE|\n",
      "+---+\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Irrespective of Case of Column\n",
    "df.select('AGE').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rocky-attitude",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 32|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "| 33|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Irrespective of Case of Column\n",
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dimensional-india",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|Age|     Category|\n",
      "+---+-------------+\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 32|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "| 33|0=Blood Donor|\n",
      "+---+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple columnns\n",
    "df.select('Age','Category').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compatible-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Age'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bracket Notation *\n",
    "df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "through-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Age'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot Notation *\n",
    "df.Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-fundamentals",
   "metadata": {},
   "source": [
    "#### Conditions & Filter\n",
    "+ df.filter\n",
    "+ df.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sixth-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "transparent-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "|_c0|   Category|Age|Sex|ALB| ALP| ALT|  AST|BIL|CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "|544|1=Hepatitis| 25|  m| 42|38.2|63.3|187.7| 14|  6|4.28|66.9|40.2|70.5|\n",
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter : Method 1\n",
    "df.filter(df['Age'] == 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aboriginal-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "|_c0|   Category|Age|Sex|ALB| ALP| ALT|  AST|BIL|CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "|544|1=Hepatitis| 25|  m| 42|38.2|63.3|187.7| 14|  6|4.28|66.9|40.2|70.5|\n",
      "+---+-----------+---+---+---+----+----+-----+---+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter : Method 1\n",
    "df.filter(df.Age == 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mysterious-enlargement",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+-----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB|  ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+-----+----+----+----+-----+----+----+----+----+\n",
      "|319|0=Blood Donor| 32|  f|39.9| 35.2|  22|29.8| 6.3| 8.16|4.37|  60| 4.5|72.5|\n",
      "|320|0=Blood Donor| 32|  f|47.4| 52.5|19.1|17.1| 4.6|10.19|  NA|  63|  23|72.2|\n",
      "|321|0=Blood Donor| 32|  f|41.1| 42.8|10.1|14.1|23.2| 6.08|3.75|  53| 9.3|68.9|\n",
      "|322|0=Blood Donor| 32|  f|43.5| 66.2| 9.2|17.8| 5.7| 7.14|4.38|  71|44.6|76.1|\n",
      "|323|0=Blood Donor| 33|  f|  36| 77.5|14.8|  22| 4.4| 8.61|5.26|  66|13.1|66.1|\n",
      "|324|0=Blood Donor| 33|  f|36.9| 51.7|17.4|  22| 8.3|    7|5.02|  52|19.1|  72|\n",
      "|325|0=Blood Donor| 33|  f|44.3|   74|49.7|52.3| 8.5| 6.49|3.34|  73|44.7|73.8|\n",
      "|326|0=Blood Donor| 33|  f|38.1| 35.2|11.9|18.3|   3| 6.09|5.22|  76|15.4|  72|\n",
      "|327|0=Blood Donor| 33|  f|  41| 61.1|  27|  28|   6| 8.36|4.93|  70|24.7|70.5|\n",
      "|328|0=Blood Donor| 33|  f|38.2| 54.4|17.3|21.2| 7.1| 8.67|5.69|  68|32.1|66.9|\n",
      "|329|0=Blood Donor| 33|  f|47.6| 95.5|18.8|22.2| 2.4| 7.84|5.57|  71|16.9|  75|\n",
      "|330|0=Blood Donor| 33|  f|42.4|137.2|14.2|13.1| 3.4| 8.23|  NA|  48|25.7|74.4|\n",
      "|331|0=Blood Donor| 33|  f|45.9|   72|37.8|33.5|17.7| 7.32|4.25|  81|21.5|78.3|\n",
      "|332|0=Blood Donor| 33|  f|35.4| 53.5| 9.8|17.6| 3.8|    6|4.48|  78|   8|71.5|\n",
      "|333|0=Blood Donor| 33|  f|38.5| 82.2|11.9|  17| 7.3| 7.23|3.92|  50|   7|73.3|\n",
      "|334|0=Blood Donor| 33|  f|41.2| 73.1|14.3|20.8|11.1|  7.4|3.22|  56|11.4|69.9|\n",
      "|335|0=Blood Donor| 33|  f|40.6| 73.7|12.6|16.3| 3.1| 7.75|6.36|  67|19.5|71.4|\n",
      "|336|0=Blood Donor| 34|  f|37.3| 36.3|19.9|28.7| 3.8|  3.9|4.94|  86| 4.9|70.7|\n",
      "|337|0=Blood Donor| 34|  f|41.9| 47.4|20.8|28.5|   8| 7.66|4.61|  97|11.2|71.9|\n",
      "|338|0=Blood Donor| 34|  f|36.3| 63.2|21.4|20.4| 4.6| 7.41|5.17|  75|18.7|64.2|\n",
      "+---+-------------+---+---+----+-----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where: Method 1\n",
    "df.where(df['sex'] == 'f').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "amended-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------+\n",
      "|Age|Sex|     Category|\n",
      "+---+---+-------------+\n",
      "| 32|  f|0=Blood Donor|\n",
      "| 32|  f|0=Blood Donor|\n",
      "| 32|  f|0=Blood Donor|\n",
      "| 32|  f|0=Blood Donor|\n",
      "| 33|  f|0=Blood Donor|\n",
      "+---+---+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where: Method 1\n",
    "df.where(df['sex'] == 'f').select('Age','Sex','Category').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "premium-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cognitive-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|Alb_by_10|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|    385.0|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|    385.0|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|    469.0|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|    432.0|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|    392.0|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|    416.0|\n",
      "|  7|0=Blood Donor| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|    463.0|\n",
      "|  8|0=Blood Donor| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|    422.0|\n",
      "|  9|0=Blood Donor| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|    509.0|\n",
      "| 10|0=Blood Donor| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|    424.0|\n",
      "| 11|0=Blood Donor| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|    443.0|\n",
      "| 12|0=Blood Donor| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|    464.0|\n",
      "| 13|0=Blood Donor| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|    363.0|\n",
      "| 14|0=Blood Donor| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|    390.0|\n",
      "| 15|0=Blood Donor| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|    387.0|\n",
      "| 16|0=Blood Donor| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|    418.0|\n",
      "| 17|0=Blood Donor| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|    409.0|\n",
      "| 18|0=Blood Donor| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|    452.0|\n",
      "| 19|0=Blood Donor| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|    366.0|\n",
      "| 20|0=Blood Donor| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|    420.0|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add A Column\n",
    "df.withColumn('Alb_by_10',df['ALB'] * 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "opening-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn('Alb_by_10',df['ALB'] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "olympic-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|Alb_by_10|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|    385.0|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|    385.0|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|    469.0|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|    432.0|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|    392.0|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|    416.0|\n",
      "|  7|0=Blood Donor| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|    463.0|\n",
      "|  8|0=Blood Donor| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|    422.0|\n",
      "|  9|0=Blood Donor| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|    509.0|\n",
      "| 10|0=Blood Donor| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|    424.0|\n",
      "| 11|0=Blood Donor| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|    443.0|\n",
      "| 12|0=Blood Donor| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|    464.0|\n",
      "| 13|0=Blood Donor| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|    363.0|\n",
      "| 14|0=Blood Donor| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|    390.0|\n",
      "| 15|0=Blood Donor| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|    387.0|\n",
      "| 16|0=Blood Donor| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|    418.0|\n",
      "| 17|0=Blood Donor| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|    409.0|\n",
      "| 18|0=Blood Donor| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|    452.0|\n",
      "| 19|0=Blood Donor| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|    366.0|\n",
      "| 20|0=Blood Donor| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|    420.0|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "laughing-breakdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|\n",
      "|  7|0=Blood Donor| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|\n",
      "|  8|0=Blood Donor| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|\n",
      "|  9|0=Blood Donor| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|\n",
      "| 10|0=Blood Donor| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|\n",
      "| 11|0=Blood Donor| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|\n",
      "| 12|0=Blood Donor| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|\n",
      "| 13|0=Blood Donor| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|\n",
      "| 14|0=Blood Donor| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|\n",
      "| 15|0=Blood Donor| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|\n",
      "| 16|0=Blood Donor| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|\n",
      "| 17|0=Blood Donor| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|\n",
      "| 18|0=Blood Donor| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|\n",
      "| 19|0=Blood Donor| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|\n",
      "| 20|0=Blood Donor| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop A Column \n",
    "df2.drop('Alb_by_10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "written-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop A Column \n",
    "df2 = df2.drop('Alb_by_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "closing-jesus",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|\n",
      "|  7|0=Blood Donor| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|\n",
      "|  8|0=Blood Donor| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|\n",
      "|  9|0=Blood Donor| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|\n",
      "| 10|0=Blood Donor| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|\n",
      "| 11|0=Blood Donor| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|\n",
      "| 12|0=Blood Donor| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|\n",
      "| 13|0=Blood Donor| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|\n",
      "| 14|0=Blood Donor| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|\n",
      "| 15|0=Blood Donor| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|\n",
      "| 16|0=Blood Donor| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|\n",
      "| 17|0=Blood Donor| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|\n",
      "| 18|0=Blood Donor| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|\n",
      "| 19|0=Blood Donor| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|\n",
      "| 20|0=Blood Donor| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "heated-bible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Category|count|\n",
      "+--------------------+-----+\n",
      "|       0=Blood Donor|  533|\n",
      "|         3=Cirrhosis|   30|\n",
      "|          2=Fibrosis|   21|\n",
      "|0s=suspect Blood ...|    7|\n",
      "|         1=Hepatitis|   24|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Counts\n",
    "# df['category'].value_counts():pandas\n",
    "df.groupBy('Category').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "removable-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "| 51|\n",
      "| 54|\n",
      "| 29|\n",
      "| 42|\n",
      "| 64|\n",
      "| 30|\n",
      "| 34|\n",
      "| 59|\n",
      "| 35|\n",
      "| 52|\n",
      "| 71|\n",
      "| 47|\n",
      "| 43|\n",
      "| 70|\n",
      "| 61|\n",
      "| 27|\n",
      "| 75|\n",
      "| 46|\n",
      "| 77|\n",
      "| 60|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Age').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fatal-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation\n",
    "# df.groupBy('category').agg('col':'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "engaging-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            category|\n",
      "+--------------------+\n",
      "|       0=Blood Donor|\n",
      "|         3=Cirrhosis|\n",
      "|          2=Fibrosis|\n",
      "|0s=suspect Blood ...|\n",
      "|         1=Hepatitis|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unique Values\n",
    "df.select('category').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mexican-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Values\n",
    "df.select('category').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "smooth-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT category)|\n",
      "+------------------------+\n",
      "|                       5|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unique Values\n",
    "df.selectExpr('count(distinct(category))').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-mentor",
   "metadata": {},
   "source": [
    "#### Save Dataset\n",
    "+ csv\n",
    "+ parquet\n",
    "+ etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "responsible-arrival",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|\n",
      "|  7|0=Blood Donor| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|\n",
      "|  8|0=Blood Donor| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|\n",
      "|  9|0=Blood Donor| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|\n",
      "| 10|0=Blood Donor| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|\n",
      "| 11|0=Blood Donor| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|\n",
      "| 12|0=Blood Donor| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|\n",
      "| 13|0=Blood Donor| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|\n",
      "| 14|0=Blood Donor| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|\n",
      "| 15|0=Blood Donor| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|\n",
      "| 16|0=Blood Donor| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|\n",
      "| 17|0=Blood Donor| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|\n",
      "| 18|0=Blood Donor| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|\n",
      "| 19|0=Blood Donor| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|\n",
      "| 20|0=Blood Donor| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "likely-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "periodic-queens",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|     Category|\n",
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|0=Blood Donor|\n",
      "| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|0=Blood Donor|\n",
      "| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|0=Blood Donor|\n",
      "| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|0=Blood Donor|\n",
      "| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|0=Blood Donor|\n",
      "| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|0=Blood Donor|\n",
      "| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|0=Blood Donor|\n",
      "| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|0=Blood Donor|\n",
      "| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|0=Blood Donor|\n",
      "| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|0=Blood Donor|\n",
      "| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|0=Blood Donor|\n",
      "| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|0=Blood Donor|\n",
      "| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|0=Blood Donor|\n",
      "| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|0=Blood Donor|\n",
      "| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|0=Blood Donor|\n",
      "| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|0=Blood Donor|\n",
      "| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT','Category').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "czech-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT','Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ignored-furniture",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o193.save.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:188)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/hcvdata_new.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o193.save.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:188)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "df.write.format('csv').option('header','true').save('data/hcvdata_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-poker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Working with SQL and Making SQL \n",
    "+ sc\n",
    "+ parse SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "medical-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "empty-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "relative-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luan Lima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('HCVTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hybrid-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL|CREA| GGT|PROT|     Category|\n",
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23| 106|12.1|  69|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8|  74|15.6|76.5|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2|  86|33.2|79.3|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74|  80|33.8|75.7|0=Blood Donor|\n",
      "| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32|  76|29.9|68.7|0=Blood Donor|\n",
      "| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05| 111|  91|  74|0=Blood Donor|\n",
      "| 32|  m|46.3|41.3|17.5|17.8| 8.5| 7.01|4.79|  70|16.9|74.5|0=Blood Donor|\n",
      "| 32|  m|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6| 109|21.5|67.1|0=Blood Donor|\n",
      "| 32|  m|50.9|65.5|23.2|21.2| 6.9| 8.69| 4.1|  83|13.7|71.3|0=Blood Donor|\n",
      "| 32|  m|42.4|86.3|20.3|  20|35.2| 5.46|4.45|  81|15.9|69.9|0=Blood Donor|\n",
      "| 32|  m|44.3|52.3|21.7|22.4|17.2| 4.15|3.57|  78|24.1|75.4|0=Blood Donor|\n",
      "| 33|  m|46.4|68.2|10.3|  20| 5.7| 7.36| 4.3|  79|18.7|68.6|0=Blood Donor|\n",
      "| 33|  m|36.3|78.6|23.6|  22|   7| 8.56|5.38|  78|19.4|68.7|0=Blood Donor|\n",
      "| 33|  m|  39|51.7|15.9|  24| 6.8| 6.46|3.38|  65|   7|70.4|0=Blood Donor|\n",
      "| 33|  m|38.7|39.8|22.5|  23| 4.1| 4.63|4.97|  63|15.2|71.9|0=Blood Donor|\n",
      "| 33|  m|41.8|  65|33.1|  38| 6.6| 8.83|4.43|  71|  24|72.7|0=Blood Donor|\n",
      "| 33|  m|40.9|  73|17.2|22.9|  10| 6.98|5.22|  90|14.7|72.4|0=Blood Donor|\n",
      "| 33|  m|45.2|88.3|32.4|31.2|10.1| 9.78|5.51| 102|48.5|76.5|0=Blood Donor|\n",
      "| 33|  m|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5| 112|27.6|69.3|0=Blood Donor|\n",
      "| 33|  m|  42|63.1|32.6|34.9|11.2| 7.01|4.05| 105|19.1|68.1|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+----+----+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make Queries\n",
    "sqlContext.sql('SELECT * FROM HCVTable').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
